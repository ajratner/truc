deepdive {

  db.default {
    driver   : "org.postgresql.Driver"
    url      : "jdbc:postgresql://"${DBHOST}":"${DBPORT}"/"${DBNAME}
    user     : ${DBUSER}
    dbname   : ${DBNAME}
    host     : ${DBHOST}
    port     : ${DBPORT}
    gphost   : ${GPHOST}
    gpport   : ${GPPORT}
    gppath   : ${GPPATH}
  }

  # Parallel grounding for GreenPlum
  inference.parallel_grounding: ${PARALLEL_GROUNDING}

  # holdout fraction for calibration
  calibration.holdout_fraction: 0.1

  # Execute one extractor at a time (but we use parallelism for extractors)
  extraction.parallelism: 1


  ### PIPELINES ###
  pipeline.run: ${PIPELINE}
  pipeline.pipelines {
    none: []
    all: [
      extract_gene_mentions,
      extract_pheno_mentions
    ]
  }


  ### EXTRACTORS ###
  extraction.extractors {

    extract_gene_mentions: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} gene_mentions
      style: tsv_extractor
      input: """
        SELECT
          table_id,
          cell_id,
          array_to_string(words, '|^|')
        FROM
          cells
      """
      output_relation: gene_mentions
      udf: ${APP_HOME}/udf/extract_gene_mentions.py
      parallelism: ${PARALLELISM}
    }

    extract_pheno_mentions: {
      before: ${APP_HOME}/util/truncate_table.sh ${DBNAME} pheno_mentions
      style: tsv_extractor
      input: """
        SELECT
          table_id,
          cell_id,
          array_to_string(words, '|^|')
        FROM
          cells
      """
      output_relation: pheno_mentions
      udf: ${APP_HOME}/udf/extract_pheno_mentions.py
      parallelism: ${PARALLELISM}
    }
  }


  ### SCHEMA ###
  schema.variables {
  }


  ### INFERENCE RULES ###
  inference.factors {
  }

  sampler.sampler_args: "-l 300 -s 1 -i 500 --alpha 0.1 --diminish 0.99 --sample_evidence"
}
